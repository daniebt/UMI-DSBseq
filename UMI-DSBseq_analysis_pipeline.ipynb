{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UMI-DSBseq Consensus Sequence Analysis WorkFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-11T04:44:59.569022Z",
     "start_time": "2021-07-11T04:44:58.165214Z"
    }
   },
   "outputs": [],
   "source": [
    "import Bio\n",
    "from Bio import SeqIO\n",
    "from Bio import Align\n",
    "from Bio import pairwise2\n",
    "from Bio.SubsMat import MatrixInfo as matlist\n",
    "from Bio.pairwise2 import format_alignment\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import cm\n",
    "import copy\n",
    "from collections import Counter\n",
    "import glob\n",
    "matrix = matlist.blosum62\n",
    "from Bio.Seq import Seq\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import math\n",
    "from Bio.Restriction import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "#### Mut_col functions for analyzing UMI-DSBseq reads following alignment\n",
    "    1. Mut_col_reverse_guide_only: in the case that the primer is oriented correctly, but the sgRNA is in reverse\n",
    "    2. Mut_col_reverse: in the case that both the primer and sgRNA are in reverse\n",
    "    3. Mut_col_Forward: in the case that the primer and sgRNA are oriented correctly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### in the case that the primer is oriented correctly, but the sgRNA is in reverse\n",
    "def Mut_col_reverse_guide_only(DFW):\n",
    "    DFW['Mut name'] = \"\"\n",
    "    DFW['position'] = \"\"\n",
    "    DFW['Left_MH'] = \"\"\n",
    "    DFW['Right_MH'] = \"\"\n",
    "    for row in DFW.iterrows():\n",
    "        wt = str(row[1].loc['WT Sequence'])\n",
    "        rgen = str(row[1].loc['RGEN Treated Sequence'])\n",
    "        guide = main_df.loc[name,'Guide sequence']\n",
    "        reference = main_df.loc[name,'WT_REF']\n",
    "\n",
    "        amplicon = Seq(wt)\n",
    "        rgen_amplicon = Seq(rgen)\n",
    "        break_site = amplicon.find(guide)+len(guide)-3\n",
    "        pam_side = amplicon[break_site:]\n",
    "        guide_side = amplicon[:break_site]\n",
    "        if row[1].loc['Type'] == 'Extended DSB': \n",
    "            if len(rgen) > 50:\n",
    "                left_end = len(rgen)-50\n",
    "                mut_name = rgen[:left_end]\n",
    "                position = 50-left_end\n",
    "                idx = f'{50-left_end}'\n",
    "                    #df.loc[index,'Mut name'] = f'+{mut_name}'\n",
    "                if wt[position:50] == mut_name:\n",
    "                    DFW.loc[row[0],'Type'] = 'guide_side DSB'\n",
    "            DFW.loc[row[0],'Mut name'] = f'+{mut_name}'\n",
    "            DFW.loc[row[0],'position'] = f'{idx}'\n",
    "            #DFW.loc[row[0],'Mut name'] = f'NaN'\n",
    "\n",
    "        if row[1].loc['Type'] == 'Resected DSB':\n",
    "            if len(rgen) < 50:\n",
    "                DFW.loc[row[0],'Type'] = 'PAM_side DSB'\n",
    "                left_end = 100-len(rgen)\n",
    "                mut_name = wt[50:left_end]\n",
    "                idx = f'{left_end}'\n",
    "            DFW.loc[row[0],'position'] = f'{idx}'\n",
    "            DFW.loc[row[0],'Mut name'] = f'-{mut_name}'\n",
    "            #DFW.loc[row[0],'Mut name'] = f'NaN'\n",
    "\n",
    "        if row[1].loc['Type'] == 'Del':\n",
    "            mut_name = \"\"\n",
    "            for le in range(min([len(wt),len(rgen)])):\n",
    "                if wt[le] != rgen[le] and rgen[le] == '-' :\n",
    "                    mut_name += wt[le]  \n",
    "            ###setting the INDEL length ##\n",
    "            indel_len = len(mut_name)\n",
    "\n",
    "            ###left end of the INDL ###\n",
    "            left_end = Seq(rgen).find('-')\n",
    "\n",
    "            ####right end of the break ###\n",
    "            right_end = left_end + indel_len-1\n",
    "\n",
    "            #extract sides of each indel\n",
    "            rev_mut_name = mut_name[::-1]\n",
    "            left_bound = wt[left_end-1]\n",
    "            right_bound = wt[right_end+1]\n",
    "\n",
    "            leftmm = wt[left_end-1] == mut_name[-1]\n",
    "            rightmm = wt[right_end+1] == mut_name[0]\n",
    "            if leftmm and rightmm == False:\n",
    "                DFW.loc[row[0],'Right_MH'] = ''\n",
    "                DFW.loc[row[0],'Left_MH'] = ''\n",
    "            if leftmm or rightmm == True:\n",
    "                DFW.loc[row[0],'Type'] = 'MH_Del'\n",
    "                Right_MH = \"\"\n",
    "                MH_Name = \"\"\n",
    "                Left_MH = \"\"\n",
    "                right_side = wt[right_end+1:]\n",
    "                left_side = wt[:left_end][::-1]\n",
    "                left_side_rev = wt[:left_end]\n",
    "\n",
    "                for le in range(len(mut_name)):\n",
    "                    if right_side[le] == mut_name[le]:\n",
    "                        Right_MH += right_side[le]\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "                DFW.loc[row[0],'Right_MH'] = f'{Right_MH}'           \n",
    "\n",
    "                for le in range(len(mut_name)):\n",
    "                    if left_side[le] == mut_name[-(le+1)]:\n",
    "                        Left_MH += mut_name[-(le+1)]\n",
    "                    else:\n",
    "                        break\n",
    "                    #print(Left_MH) \n",
    "                DFW.loc[row[0],'Left_MH'] = f'{Left_MH}'\n",
    "            left_position_border = left_end-1\n",
    "            right_position_border = right_end+1\n",
    "            idx = f'{left_position_border}'+'_'+f'{right_position_border}'\n",
    "                #x = left_end - 1\n",
    "            DFW.loc[row[0],'position'] = f'{idx}'            \n",
    "            DFW.loc[row[0],'Mut name'] = f'-{mut_name}'\n",
    "        else:\n",
    "            DFW.loc[row[0],'Right_MH'] = ''\n",
    "            DFW.loc[row[0],'Left_MH'] = ''\n",
    "\n",
    "        if row[1].loc['Type'] == 'Perfect DSB':\n",
    "            wt = row[1].loc['WT Sequence']\n",
    "            rgen = row[1].loc['RGEN Treated Sequence']\n",
    "            #left_end = Seq(rgen).find('-')\n",
    "            #idx = f'I{left_end}' \n",
    "            if len(rgen) == 50:\n",
    "                mut_name = 'precise'\n",
    "                left_end = len(rgen)\n",
    "                idx = f'{left_end}'\n",
    "            DFW.loc[row[0],'position'] = f'{idx}'\n",
    "            DFW.loc[row[0],'Mut name'] = f'{mut_name}'\n",
    "        \n",
    "        if row[1].loc['Type'] == 'Ins':\n",
    "            mut_name = \"\"\n",
    "            for le in range(min([len(wt),len(rgen)])):\n",
    "                if wt[le] != rgen[le] and wt[le] == '-' :\n",
    "                    mut_name += rgen[le]\n",
    "\n",
    "            ###setting the INDEL length ##\n",
    "            indel_len = len(mut_name)\n",
    "\n",
    "            ###left end of the INDL ###\n",
    "            left_end = Seq(wt).find('-')\n",
    "\n",
    "            idx = f'{left_end}'\n",
    "            #x = left_end - 1\n",
    "            DFW.loc[row[0],'position'] = f'{left_end}'\n",
    "            DFW.loc[row[0],'Mut name'] = f'+{mut_name}'\n",
    "            DFW.loc[row[0],'Right_MH'] = ''\n",
    "            DFW.loc[row[0],'Left_MH'] = ''\n",
    "    return(DFW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-11T04:45:04.288008Z",
     "start_time": "2021-07-11T04:45:04.270310Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### in the case that both the primer and sgRNA are in reverse\n",
    "def Mut_col_reverse(DFW):\n",
    "    DFW['Mut name'] = \"\"\n",
    "    DFW['position'] = \"\"\n",
    "    DFW['Left_MH'] = \"\"\n",
    "    DFW['Right_MH'] = \"\"\n",
    "    for row in DFW.iterrows():\n",
    "        wt = str(row[1].loc['WT Sequence'])\n",
    "        rgen = str(row[1].loc['RGEN Treated Sequence'])\n",
    "        guide = main_df.loc[name,'Guide sequence']\n",
    "        reference = main_df.loc[name,'WT_REF']\n",
    "\n",
    "        amplicon = Seq(wt)\n",
    "        rgen_amplicon = Seq(rgen)\n",
    "\n",
    "        amplicon = amplicon.reverse_complement()\n",
    "        temp_rgen = Seq(rgen)\n",
    "        rgen = str(temp_rgen.reverse_complement())\n",
    "        temp_wt = Seq(wt)\n",
    "        wt = str(temp_wt.reverse_complement())\n",
    "\n",
    "        break_site = amplicon.find(guide)+len(guide)-3\n",
    "        pam_side = amplicon[break_site:]\n",
    "        guide_side = amplicon[:break_site]\n",
    "\n",
    "        if row[1].loc['Type'] == 'Extended DSB': \n",
    "            if len(rgen) > 50:\n",
    "                left_end = len(rgen)-50\n",
    "                mut_name = rgen[:left_end]\n",
    "                position = 50-left_end\n",
    "                idx = f'{50-left_end}'\n",
    "                if wt[position:50] == mut_name:\n",
    "                    DFW.loc[row[0],'Type'] = 'guide_side DSB'\n",
    "            DFW.loc[row[0],'Mut name'] = f'+{mut_name}'\n",
    "            DFW.loc[row[0],'position'] = f'{idx}'\n",
    "\n",
    "        if row[1].loc['Type'] == 'Resected DSB':\n",
    "            if len(rgen) < 50:\n",
    "                DFW.loc[row[0],'Type'] = 'PAM_side DSB'\n",
    "                left_end = 100-len(rgen)\n",
    "                mut_name = wt[50:left_end]\n",
    "                idx = f'{left_end}'\n",
    "            DFW.loc[row[0],'position'] = f'{idx}'\n",
    "            DFW.loc[row[0],'Mut name'] = f'-{mut_name}'\n",
    "\n",
    "        if row[1].loc['Type'] == 'Del':\n",
    "            mut_name = \"\"\n",
    "            for le in range(min([len(wt),len(rgen)])):\n",
    "                if wt[le] != rgen[le] and rgen[le] == '-' :\n",
    "                    mut_name += wt[le]  \n",
    "            ###setting the INDEL length ##\n",
    "            indel_len = len(mut_name)\n",
    "\n",
    "            ###left end of the INDL ###\n",
    "            left_end = Seq(rgen).find('-')\n",
    "\n",
    "            ####right end of the break ###\n",
    "            right_end = left_end + indel_len-1\n",
    "\n",
    "            #extract sides of each indel\n",
    "            rev_mut_name = mut_name[::-1]\n",
    "            left_bound = wt[left_end-1]\n",
    "            right_bound = wt[right_end+1]\n",
    "\n",
    "            leftmm = wt[left_end-1] == mut_name[-1]\n",
    "            rightmm = wt[right_end+1] == mut_name[0]\n",
    "            if leftmm and rightmm == False:\n",
    "                DFW.loc[row[0],'Right_MH'] = ''\n",
    "                DFW.loc[row[0],'Left_MH'] = ''\n",
    "            if leftmm or rightmm == True:\n",
    "                DFW.loc[row[0],'Type'] = 'MH_Del'\n",
    "                Right_MH = \"\"\n",
    "                MH_Name = \"\"\n",
    "                Left_MH = \"\"\n",
    "                right_side = wt[right_end+1:]\n",
    "                left_side = wt[:left_end][::-1]\n",
    "                left_side_rev = wt[:left_end]\n",
    "                for le in range(len(mut_name)):\n",
    "                    if right_side[le] == mut_name[le]:\n",
    "                        Right_MH += right_side[le]\n",
    "                    else:\n",
    "                        break\n",
    "                DFW.loc[row[0],'Right_MH'] = f'{Right_MH}'           \n",
    "                for le in range(len(mut_name)):\n",
    "                    if left_side[le] == mut_name[-(le+1)]:\n",
    "                        Left_MH += mut_name[-(le+1)]\n",
    "                    else:\n",
    "                        break\n",
    "                DFW.loc[row[0],'Left_MH'] = f'{Left_MH}'\n",
    "            left_position_border = left_end-1\n",
    "            right_position_border = right_end+1\n",
    "            idx = f'{left_position_border}'+'_'+f'{right_position_border}'\n",
    "            DFW.loc[row[0],'position'] = f'{idx}'            \n",
    "            DFW.loc[row[0],'Mut name'] = f'-{mut_name}'\n",
    "        else:\n",
    "            DFW.loc[row[0],'Right_MH'] = ''\n",
    "            DFW.loc[row[0],'Left_MH'] = ''\n",
    "        if row[1].loc['Type'] == 'Perfect DSB':\n",
    "            wt = row[1].loc['WT Sequence']\n",
    "            rgen = row[1].loc['RGEN Treated Sequence']\n",
    "            if len(rgen) == 50:\n",
    "                mut_name = 'precise'\n",
    "                left_end = len(rgen)\n",
    "                idx = f'{left_end}'\n",
    "            DFW.loc[row[0],'position'] = f'{idx}'\n",
    "            DFW.loc[row[0],'Mut name'] = f'{mut_name}'\n",
    "        if row[1].loc['Type'] == 'Ins':\n",
    "            mut_name = \"\"\n",
    "            for le in range(min([len(wt),len(rgen)])):\n",
    "                if wt[le] != rgen[le] and wt[le] == '-' :\n",
    "                    mut_name += rgen[le]\n",
    "            ###setting the INDEL length ##\n",
    "            indel_len = len(mut_name)\n",
    "            ###left end of the INDL ###\n",
    "            left_end = Seq(wt).find('-')\n",
    "            idx = f'{left_end}'\n",
    "            DFW.loc[row[0],'position'] = f'{left_end}'\n",
    "            DFW.loc[row[0],'Mut name'] = f'+{mut_name}'\n",
    "            DFW.loc[row[0],'Right_MH'] = ''\n",
    "            DFW.loc[row[0],'Left_MH'] = ''\n",
    "    return(DFW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-11T04:45:06.702597Z",
     "start_time": "2021-07-11T04:45:06.686748Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### in the case that the primer and sgRNA are oriented correctly\n",
    "def Mut_col_Forward(DFW):\n",
    "    DFW['Mut name'] = \"\"\n",
    "    DFW['position'] = \"\"\n",
    "    DFW['Left_MH'] = \"\"\n",
    "    DFW['Right_MH'] = \"\"\n",
    "    for row in DFW.iterrows():\n",
    "        wt = row[1].loc['WT Sequence']\n",
    "        rgen = row[1].loc['RGEN Treated Sequence']\n",
    "        guide = main_df.loc[name,'Guide sequence']\n",
    "        reference = main_df.loc[name,'WT_REF']\n",
    "        wt=str(wt)\n",
    "        rgen=str(rgen)\n",
    "        amplicon = Seq(wt)\n",
    "        rgen_amplicon = Seq(rgen)\n",
    "\n",
    "        break_site = amplicon.find(guide)+len(guide)-3\n",
    "        pam_side = amplicon[break_site:]\n",
    "        guide_side = amplicon[:break_site]\n",
    "\n",
    "        if row[1].loc['Type'] == 'Perfect DSB':\n",
    "            if len(rgen) == 50:\n",
    "                mut_name = 'precise'\n",
    "                left_end = len(rgen)-1\n",
    "                idx = f'{left_end}'\n",
    "            DFW.loc[row[0],'position'] = f'{idx}'\n",
    "            DFW.loc[row[0],'Mut name'] = f'{mut_name}'\n",
    "\n",
    "        if row[1].loc['Type'] == 'Extended DSB': \n",
    "            mut_name = \"\"\n",
    "            if len(rgen) > 50:\n",
    "                left_end = len(rgen)\n",
    "                mut_name = rgen[50:]\n",
    "                position = left_end\n",
    "                if wt[50:position] == mut_name:\n",
    "                    DFW.loc[row[0],'Type'] = 'PAM_side DSB'\n",
    "                left_position_border = left_end-1\n",
    "                idx = f'{left_position_border}'\n",
    "            DFW.loc[row[0],'Mut name'] = f'+{mut_name}'\n",
    "            DFW.loc[row[0],'position'] = f'{idx}'\n",
    "\n",
    "        if row[1].loc['Type'] == 'Resected DSB':\n",
    "            mut_name = \"\"                \n",
    "            if len(rgen) < 50:\n",
    "                DFW.loc[row[0],'Type'] = 'guide_side DSB'\n",
    "                left_end = len(rgen)\n",
    "                mut_name = wt[left_end:50]\n",
    "                left_position_border = left_end-1\n",
    "                idx = f'{left_position_border}'\n",
    "                \n",
    "            DFW.loc[row[0],'position'] = f'{idx}'\n",
    "            DFW.loc[row[0],'Mut name'] = f'-{mut_name}'\n",
    "            \n",
    "        if row[1].loc['Type'] == 'Del':\n",
    "            mut_name = \"\"\n",
    "            for le in range(min([len(wt),len(rgen)])):\n",
    "                if wt[le] != rgen[le] and rgen[le] == '-' :\n",
    "                    mut_name += wt[le]  \n",
    "            ###setting the INDEL length ##\n",
    "            indel_len = len(mut_name)\n",
    "\n",
    "            ###left end of the INDL ###\n",
    "            left_end = Seq(rgen).find('-')\n",
    "\n",
    "            ####right end of the break ###\n",
    "            right_end = left_end + indel_len-1\n",
    "\n",
    "            #extract sides of each indel\n",
    "            rev_mut_name = mut_name[::-1]\n",
    "            left_bound = wt[left_end-1]\n",
    "            right_bound = wt[right_end+1]\n",
    "\n",
    "            leftmm = wt[left_end-1] == mut_name[-1]\n",
    "            rightmm = wt[right_end+1] == mut_name[0]\n",
    "            if leftmm and rightmm == False:\n",
    "                DFW.loc[row[0],'Right_MH'] = ''\n",
    "                DFW.loc[row[0],'Left_MH'] = ''\n",
    "            if leftmm or rightmm == True:\n",
    "                DFW.loc[row[0],'Type'] = 'MH_Del'\n",
    "                Right_MH = \"\"\n",
    "                MH_Name = \"\"\n",
    "                Left_MH = \"\"\n",
    "                right_side = wt[right_end+1:]\n",
    "                left_side = wt[:left_end][::-1]\n",
    "                left_side_rev = wt[:left_end]\n",
    "\n",
    "                for le in range(len(mut_name)):\n",
    "                    if right_side[le] == mut_name[le]:\n",
    "                        Right_MH += right_side[le]\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "                DFW.loc[row[0],'Right_MH'] = f'{Right_MH}'           \n",
    "\n",
    "                for le in range(len(mut_name)):\n",
    "                    if left_side[le] == mut_name[-(le+1)]:\n",
    "                        Left_MH += mut_name[-(le+1)]\n",
    "                    else:\n",
    "                        break\n",
    "                DFW.loc[row[0],'Left_MH'] = f'{Left_MH}'\n",
    "            left_position_border = left_end-1\n",
    "            right_position_border = right_end+1\n",
    "            idx = f'{left_position_border}'+'_'+f'{right_position_border}'\n",
    "            DFW.loc[row[0],'position'] = f'{idx}'            \n",
    "            DFW.loc[row[0],'Mut name'] = f'-{mut_name}'\n",
    "        else:\n",
    "            DFW.loc[row[0],'Right_MH'] = ''\n",
    "            DFW.loc[row[0],'Left_MH'] = ''\n",
    "        \n",
    "        if row[1].loc['Type'] == 'Ins':\n",
    "            mut_name = \"\"\n",
    "            for le in range(min([len(wt),len(rgen)])):\n",
    "                if wt[le] != rgen[le] and wt[le] == '-' :\n",
    "                    mut_name += rgen[le]\n",
    "\n",
    "            ###setting the INDEL length ##\n",
    "            indel_len = len(mut_name)\n",
    "\n",
    "            ###left end of the INDL ###\n",
    "            left_end = Seq(wt).find('-')\n",
    "\n",
    "            idx = f'{left_end}'\n",
    "            DFW.loc[row[0],'position'] = f'{left_end}'\n",
    "            DFW.loc[row[0],'Mut name'] = f'+{mut_name}'\n",
    "            DFW.loc[row[0],'Right_MH'] = ''\n",
    "            DFW.loc[row[0],'Left_MH'] = ''\n",
    "    return(DFW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-11T04:45:11.606294Z",
     "start_time": "2021-07-11T04:45:11.603436Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_data_from_xlsx(fname):\n",
    "    df_samp = pd.read_excel(fname)\n",
    "    df_samp = df_samp.set_index('Sample Name')### generating DF from elsx file form curnt dir \n",
    "    return(df_samp)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-11T04:45:02.290445Z",
     "start_time": "2021-07-11T04:45:02.286884Z"
    }
   },
   "outputs": [],
   "source": [
    "def Calculate_average(data):\n",
    "    #Calculate average based on ordered duplicates\n",
    "    data = data.T\n",
    "    avg_NHEJ = data.groupby(np.arange(len(data.index))//2).mean() \n",
    "    avg_NHEJ.index = avg_names\n",
    "    return(avg_NHEJ)\n",
    "avg_names = [0,6,12,24,36,48,72]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.User Input\n",
    "    name of target (target_name) - for naming output\n",
    "    directory containing joined-fastqs and Sample_data.xlxs (my_dir), \n",
    "    Sample_data.xlxs file: must be placed in fastq-join folder\n",
    "        Required columns, rows for each sample in time-course:\n",
    "             'library name': name of fastq-join file\n",
    "             'Sample Name': name of sample\n",
    "             'Guide sequence': sgRNA 20bp sequence (no PAM)\n",
    "             'Amplicon sequence': expected sequence of wt intact molecule (primer--> restriction site:\n",
    "             'forward_primer': sequene of target-specific amplification primer\n",
    "             'restricted_end': expected 5 bp end of amplicon at end-repaired restrictioin site \n",
    "#### EXAMPLE\n",
    "     target_name = 'Psy1'\n",
    "     restricted_end = 'GTCCG'#enter 5bp end of amplicon at the restriction site\n",
    "     imprecise_end='' #enter sequence for direct filtering\n",
    "     my_dir = '/fastq_join/'\n",
    "## 2. Create 100bp reference sequence\n",
    "    reads in Sample_data.xlxs file\n",
    "    extracts reference sequence from WT_ref (50bp to each side of DSB using Guide sequence and Amplicon sequence)\n",
    "## 3. Convert fastq-join to table of id, read sequence, wt sequence \n",
    "    Parse fastq-joined files using SeqIO, make simple table for further processessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = input('''ENTER Name of target\n",
    "# will be used for naming output \\n''')\n",
    "imprecise_end = input('''ENTER last 5bp of sequence to filter OUT  - press enter if none - \n",
    "# will be used for filtering of desired sequence \\n''')\n",
    "my_dir = input('''ENTER YOUR FASTQ-JOIN DIRECTORY\n",
    "# ...PATH_TO/fastq-join/\\n''')\n",
    "save_dir = input('''ENTER PATH to DIRECTORY for saving\n",
    "# ...PATH_TO/save_dir/\\n''')\n",
    "\n",
    "os.chdir(my_dir)\n",
    "main_df = sample_data_from_xlsx(\"Sample_data.xlsx\")\n",
    "time_names = list(main_df.index)\n",
    "for idx in time_names:\n",
    "    if main_df.loc[idx,'Guide sequence'] not in main_df.loc[idx,'Amplicon sequence'] :\n",
    "        seq_rev = Seq(main_df.loc[idx,'Amplicon sequence'] ).reverse_complement()\n",
    "        main_df.loc[idx,'Amplicon sequence']  = seq_rev\n",
    "    main_df.loc[idx,'Guide sequence'] = main_df.loc[idx,'Guide sequence'].upper()\n",
    "    main_df.loc[idx,'Amplicon sequence'] = main_df.loc[idx,'Amplicon sequence'].upper()\n",
    "    L_end = (main_df.loc[idx,'Amplicon sequence'].find(main_df.loc[idx,'Guide sequence'])+len(main_df.loc[idx,'Guide sequence'])-3 - 50 )    \n",
    "    if L_end < 0: \n",
    "        L_end = 0\n",
    "    R_end = ( main_df.loc[idx,'Amplicon sequence'].find(main_df.loc[idx,'Guide sequence'])+len(main_df.loc[idx,'Guide sequence'])-3 + 50)\n",
    "    main_df.loc[idx,'WT_REF'] =  main_df.loc[idx,'Amplicon sequence'][L_end:R_end]   \n",
    "    if type(main_df.loc[idx,'WT_REF']) != Bio.Seq.Seq:\n",
    "        main_df.loc[idx,'WT_REF'] = Seq(main_df.loc[idx,'WT_REF'])\n",
    "    print(f\"{idx} -->len {len(main_df.loc[idx,'WT_REF'] )}\")\n",
    "    \n",
    "dict_of_all_samples = {}\n",
    "for idx in time_names:\n",
    "    time = str(main_df.loc[idx,'library name'])\n",
    "    file_name =f\"{time}.join.fastq\"\n",
    "    file_path = my_dir+file_name\n",
    "    table = pd.DataFrame(columns=['records','seq_id','seq'])#creates empty table with columns \n",
    "    records = list(SeqIO.parse(file_name, \"fastq\"))#parse the fastq one by one\n",
    "    print(\"Starting analysis of %s ...\" % time)\n",
    "    print(\"    Processing %i Reads\" % len(records))\n",
    "    table.loc[:,'records'] = records\n",
    "    table.loc[:, 'seq_id'] = table.records.map(lambda  x: x.id)\n",
    "    table.loc[:, 'seq'] = table.records.map(lambda  x: x.seq)       \n",
    "    table.loc[:, 'seq_length'] = table.records.map(lambda  x:  len(str(x.seq[3:])))\n",
    "    key_name = str(idx) #name dataframe of reads for the sample    \n",
    "    dict_of_all_samples[key_name] = copy.deepcopy(table) #save dataframe to all_sample dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define state of read: Intact vs. DSB\n",
    "     align the last 12bp at each end of the 100bp WT reference window (ali1 and ali) to each read\n",
    "         intact = both ali1 and ali2 >10/12 match to pass\n",
    "         DSB = only ali1 >10/12 match to pass\n",
    "         filter out = only ali2 >10/12 match to pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-11T04:47:39.850798Z",
     "start_time": "2021-07-11T04:45:30.358351Z"
    }
   },
   "outputs": [],
   "source": [
    "def pass_filter(df, label, length, pass_type):\n",
    "    text_data = df[label].tolist()\n",
    "    text_length = pd.Series([len(t) for t in text_data])\n",
    "    df = df.assign(text_length=text_length .values)\n",
    "    if pass_type == 'high':\n",
    "        df = df[df.text_length > length]\n",
    "    if pass_type == 'low':\n",
    "        df = df[df.text_length < length]\n",
    "    df = df.drop(columns=['text_length'])\n",
    "    return df\n",
    "\n",
    "\n",
    "for name, df in dict_of_all_samples.items():\n",
    "    print(\"Begin calling states for reads in %s ...\" % name)\n",
    "        ####Extracting region around the DSB site, aligning to reference sequence#####\n",
    "\n",
    "        # Determine the sequence of the 12bp indicators at the ends of the 100bp window surrounding the DSB site\n",
    "    amplicon_seq = main_df.loc[name,'Amplicon sequence']\n",
    "    primer = main_df.loc[name,'forward_primer']\n",
    "    \n",
    "   # Determine the sequence of the 12bp indicators at the ends of the 100bp window surrounding the DSB site\n",
    "    if primer in amplicon_seq:\n",
    "        Side1 = main_df.loc[name, 'WT_REF'][0:12]\n",
    "        Side2 = main_df.loc[name, 'WT_REF'][-12:]\n",
    "\n",
    "    # reverse complement the reference window wt_ref, if necessary,\n",
    "    else:\n",
    "        print('reversing sides')\n",
    "        temp_wt_ref = main_df.loc[name, 'WT_REF'].reverse_complement()\n",
    "        Side1 = temp_wt_ref[0:12]\n",
    "        Side2 = temp_wt_ref[-12:]\n",
    "\n",
    "    # activate the run time calculator tqdm\n",
    "    tqdm.pandas(desc=\"align sides\")\n",
    "    # Align the 12bp indicators to the read (seq variable) and enter alignment into dataframe\n",
    "    df.loc[:, 'Ali_side1'] = df.seq.progress_map(\n",
    "        lambda x: pairwise2.align.localxs(x, Side1, -5, -4, one_alignment_only=True))\n",
    "    df.loc[:, 'Ali_side2'] = df.seq.progress_map(\n",
    "        lambda x: pairwise2.align.localxs(x, Side2, -5, -4, one_alignment_only=True))\n",
    "\n",
    "    df = pass_filter(df, 'Ali_side1', 0, 'high')\n",
    "    # determine the alignment score of each 12bp indicator and enter into dataframe\n",
    "    df.loc[:, 'Ali1_score'] = df.Ali_side1.progress_map(lambda x: x[0][2])\n",
    "    df.loc[:, 'Ali2_score'] = df.Ali_side2.progress_map(lambda x: x[0][2])\n",
    "\n",
    "    # Define Intact molecules using cut of alignment of the 12bp indicator allowing for 2 mismatches\n",
    "    df.loc[(df['Ali1_score'] >= 10) & (\n",
    "        df['Ali2_score'] >= 10), 'state'] = 'Intact'\n",
    "    df.loc[(df['state'] != 'Intact'), 'state'] = 'NA'\n",
    "    # Determine the location of the indicators in the sequence and enter them into the dataframe\n",
    "    df.loc[:, 'seq3_Lside'] = df.Ali_side1.map(lambda x: x[0][3])\n",
    "    df.loc[:, 'seq3_Rside'] = df.Ali_side2.map(lambda x: x[0][4])\n",
    "\n",
    "  # Define seq window of interest based on the state, Intact molecules for amplicon sequencing with further processing for putative DSBs in the UMI-DSB libraries\n",
    "\n",
    "    df.loc[(df['state'] == 'Intact'), 'seq_window'] = df.apply(\n",
    "        lambda x: x['seq'][x['seq3_Lside']:x['seq3_Rside']], axis=1)\n",
    "    df.loc[(df['state'] == 'NA'), 'seq_window'] = df.apply(\n",
    "        lambda x: x['seq'][x['seq3_Lside']:], axis=1)\n",
    "\n",
    "    # Calculate the length of the window of interest and enter into Dataframe with column name length_seq_window\n",
    "    df.loc[:, 'length_seq_window'] = df['seq_window'].str.len()\n",
    "\n",
    "    # Define DSBs\n",
    "\n",
    "    df.loc[(df['state'] == 'NA') & (df['Ali1_score'] >= 10) & (\n",
    "        df['Ali2_score'] < 10) & (df['length_seq_window'] < 90), 'state'] = 'Putative DSB'\n",
    "\n",
    "    # Mark reads with more than 4 Ns as 'NA'\n",
    "    df.loc[:, 'N_count'] = df.seq_window.map(lambda x: x.count('N'))\n",
    "    df.loc[(df['N_count'] > 4), 'state'] = 'NA'\n",
    "\n",
    "    # save the df to the sample dictionary\n",
    "    dict_of_all_samples[name] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Filter Intact reads\n",
    "    uses the restriced_end expected at each target \n",
    "    grouping reads by sequence within the 100 bp window of interest\n",
    "    adding a column 'count'- serves to reduce number of sequences needing alignment in the next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_all_end_filtered_reads = copy.deepcopy(dict_of_all_samples)\n",
    "imprecise_end_list = []\n",
    "restricted_end = str(main_df.loc[name, 'restricted_end'])\n",
    "for name, df in dict_of_all_end_filtered_reads.items():\n",
    "    for index, data in tqdm(df.iterrows()):\n",
    "        if df.loc[index, 'state'] == 'Intact':\n",
    "            if df.loc[index, 'seq'].endswith(restricted_end):\n",
    "                df.loc[index,'endswith'] = 'precise'\n",
    "            if len(imprecise_end)>2:\n",
    "                if df.loc[index, 'seq'].endswith(imprecise_end):\n",
    "                    df.loc[index,'endswith'] = 'contamination'\n",
    "                    df.loc[index,'state'] = 'contamination'\n",
    "            else:\n",
    "                df.loc[index,'endswith'] = 'imprecise'\n",
    "            df.loc[index,'end'] = df.loc[index,'seq'][-10:]\n",
    "    dict_of_all_end_filtered_reads[name] = df\n",
    "    \n",
    "dict_of_all_grouped = copy.deepcopy(dict_of_all_end_filtered_reads)\n",
    "for name, df in dict_of_all_grouped.items():\n",
    "    print(\"Begin calling states for reads in %s ...\" % name)\n",
    "    df = df.groupby(['seq_window','length_seq_window','state'],as_index = False).count()\n",
    "    df=df.drop(columns = ['seq_id','seq', 'seq_length',\n",
    "    'Ali1_score', 'Ali2_score', 'seq3_Rside',\n",
    "    'seq3_Lside', 'N_count'])\n",
    "    df =df.rename(columns={'records' : 'count'})\n",
    "    dict_of_all_grouped[name] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Characterizing consensus sequences\n",
    "    Uses local alignment to the WT reference (given in the sample sheet) to characterize the consensus sequences\n",
    "    Defines each Intact sequence as either WT or Indel (insertion/deletion)\n",
    "        indels are further divided into insertions (Ins) and deletions (Del)\n",
    "    Defines unrepaired DSBs\n",
    "        Precise DSB: exactly at the expected position with a length of 50 bp\n",
    "        guide-side DSB: position is shifted towards the sgRNA sequence\n",
    "        PAM-side DSB: position is shifted towards the PAM sequence\n",
    "        Extended DSB: longer than expected DSB of >50 bp with extension that does not match the reference sequence\n",
    "    Calling indels and DSB names using Mut_col function according to their missing or added bases \n",
    "        Places those in columns 'Mut name' and 'DSB name' respectively\n",
    "    Identifies any microhomology around the deletions, \n",
    "    groups and counts the sequences by all parameters.\n",
    "        *changing window sizes requires adjusting the expected window length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-11T04:57:49.554433Z",
     "start_time": "2021-07-11T04:57:34.217493Z"
    }
   },
   "outputs": [],
   "source": [
    "dict_of_all_types = copy.deepcopy(dict_of_all_grouped)\n",
    "for name, df in dict_of_all_types.items():\n",
    "        #activate the run time calculator tqdm\n",
    "    print(name)\n",
    "   \n",
    "    tqdm.pandas(desc=\"align reads\")\n",
    "    print(\"Begin alignment reads in %s ...\" % name)\n",
    "    reference = main_df.loc[name,'WT_REF']\n",
    "    reference_rev = main_df.loc[name,'WT_REF'].reverse_complement()\n",
    "    #df.loc['alignments'] = df['alignments'].astype('object')\n",
    "    df['alignments']  = ''\n",
    "    df['alignments'] = df['alignments'].astype('object')\n",
    "    guide = main_df.loc[name,'Guide sequence']\n",
    "    amplicon_seq = main_df.loc[name,'Amplicon sequence']\n",
    "    primer = main_df.loc[name,'forward_primer']\n",
    "    for index, data in tqdm(df.iterrows()):\n",
    "        if (data['state'] != 'NA') and data['length_seq_window'] > 0  :\n",
    "            if primer in amplicon_seq:\n",
    "                if guide in amplicon_seq:\n",
    "                    df.at[index,'alignments'] = pairwise2.align.localxs(reference,data['seq_window'], -1, 0,one_alignment_only = True)\n",
    "            else:\n",
    "                df.at[index,'alignments'] = pairwise2.align.localxs(reference,data['seq_window'].reverse_complement(), -1, 0,one_alignment_only = True)\n",
    "        else:\n",
    "             df.at[index,'alignments'] = 'NA'\n",
    "    \n",
    "    print(\"Begin calling read types %s ...\" % name)\n",
    "    for index, data in tqdm(df.iterrows()):\n",
    "        if data['state'] == 'Intact' and data['length_seq_window'] > 0 :\n",
    "            \n",
    "            wt = df.loc[index,'alignments'][0][0].strip('-')\n",
    "            rgen = df.loc[index,'alignments'][0][1].strip('-')\n",
    "            \n",
    "            df.loc[index,'RGEN Treated Sequence'] = str(rgen)\n",
    "            df.loc[index,'WT Sequence'] = str(wt)\n",
    "\n",
    "            if rgen.find('-') == -1 and wt.find('-') != -1 :\n",
    "                df.loc[index,'Type'] = 'Ins'\n",
    "                df.loc[index,'state'] = 'NHEJ'\n",
    "            elif rgen.find('-') != -1 and wt.find('-') == -1:\n",
    "                df.loc[index,'Type'] = 'Del'\n",
    "                df.loc[index,'state'] = 'NHEJ'\n",
    "            else:\n",
    "                df.loc[index,'Type'] = 'WT/Sub'\n",
    "                \n",
    "            if wt.startswith('N') == True:\n",
    "                    df.loc[index,'RGEN Treated Sequence'] = str('N'+rgen)\n",
    "            if wt.endswith('N')==True:\n",
    "                    df.loc[index,'RGEN Treated Sequence'] = str(rgen+'N')\n",
    "    \n",
    "        if data['state'] == 'Putative DSB' and data['length_seq_window'] > 0 :\n",
    "            wt = df.loc[index,'alignments'][0][0].strip('-')\n",
    "            rgen = df.loc[index,'alignments'][0][1].replace('-', '')\n",
    "            df.loc[index,'WT Sequence'] = wt\n",
    "            df.loc[index,'RGEN Treated Sequence'] = rgen\n",
    "        else:\n",
    "            if data['state'] == 'NA':\n",
    "                df.loc[index,'RGEN Treated Sequence'] = 'NA'\n",
    "                df.loc[index,'WT Sequence'] = 'NA'\n",
    "        ###setting the guide and amplicon seq ##\n",
    "    df.loc[(df['state'] == 'Putative DSB') & (df['length_seq_window'] == 50),'Type'] = 'Perfect DSB'\n",
    "    df.loc[(df['state'] == 'Putative DSB') & (df['length_seq_window'] > 50),'Type'] = 'Extended DSB'\n",
    "    df.loc[(df['state'] == 'Putative DSB') & (df['length_seq_window'] < 50),'Type'] = 'Resected DSB'\n",
    "\n",
    "    # reverse complement the reference window wt_ref, if necessary\n",
    "    if primer in amplicon_seq:            \n",
    "        if guide in amplicon_seq:\n",
    "            Mut_col_Forward(df)       \n",
    "        else:\n",
    "            print(f'guide not found: reversing orientation')\n",
    "            Mut_col_reverse(df)\n",
    "    else:  \n",
    "        print(f'reversing orientation')\n",
    "        Mut_col_reverse_guide_only(df)\n",
    "#     Mut_col_Forward(df)       \n",
    "\n",
    "    dict_of_all_types[name] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T17:21:45.519619Z",
     "start_time": "2021-01-24T17:21:45.505842Z"
    }
   },
   "source": [
    "## 7. Group reads and count \n",
    "     retains columns sequence, length, sate, type, mut name, DSB\n",
    "## 8. Identify microhomology associated deletions\n",
    "    cut-off can be manually adjusted, default is 2 bp minimum microhomology\n",
    "## 9. Output all csv. files of fully characterized grouped, counted consensus sequences for each sample \n",
    "    saved in directory /save_dir/target_name_all_grouped_reads_csv/'\n",
    "    [sample]_all_grouped_reads.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-11T04:58:03.253193Z",
     "start_time": "2021-07-11T04:58:03.108260Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_of_all_types_grouped = copy.deepcopy(dict_of_all_types)\n",
    "for name, df in dict_of_all_types_grouped.items():\n",
    "    print(\"Begin calling states for reads in %s ...\" % name)\n",
    "    df = df.groupby(['seq_window','length_seq_window','state','Type','Mut name','position','Right_MH','Left_MH'],as_index = False).agg({'count':'sum'})\n",
    "    dict_of_all_types_grouped[name] = df\n",
    "\n",
    "dict_of_all_grouped_MH = copy.deepcopy(dict_of_all_types_grouped)\n",
    "for name, df in dict_of_all_grouped_MH.items():\n",
    "    df.loc[(df['Type'] == 'MH_Del') & (df['Left_MH'].str.len() >= 2),'Type'] = 'MH_Del_2+'\n",
    "    df.loc[(df['Type'] == 'MH_Del') & (df['Right_MH'].str.len() >= 2),'Type'] = 'MH_Del_2+'\n",
    "    df.loc[(df['Type'] == 'MH_Del') & (df['Left_MH'].str.len() < 2) & (df['Left_MH'].str.len() < 2),'Type'] = 'Del'\n",
    "    print(\"Begin calling MH sizes for reads in %s ...\" % name)\n",
    "    dict_of_all_grouped_MH[name] = df\n",
    "\n",
    "os.mkdir(save_dir+target_name+'_all_grouped_reads_csv')\n",
    "for name, df in dict_of_all_grouped_MH.items():\n",
    "    print(name)\n",
    "    df.to_csv(save_dir+target_name+'_all_grouped_reads_csv'+'/'+name+'_all_grouped_reads.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Produce individual summary tables of counts for each of  for States, Types, Indels, and DSBs \n",
    "    states: Intact, Putative DSB, NHEJ\n",
    "    types: Insertion, Deletion, Precise DSB, Extended DSB, Resected DSB\n",
    "        Makes Tables of counts and percentages for all samples:\n",
    "      [target_name]_States_df.csv: Indels, Intact (WT), DSB \n",
    "      [target_name]_Types_MH_df.csv: input to kinetics pipeline \n",
    "      [target_name]_indel.csv: error-prone repair footprints\n",
    "      [target_name]_DSB.csv:specific DSBs by position and other characteristics \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T10:32:09.377706Z",
     "start_time": "2021-06-28T10:32:06.390371Z"
    }
   },
   "outputs": [],
   "source": [
    "dict_of_all_type_sums = {}\n",
    "dict_of_all_state_sums = {}\n",
    "dict_of_all_indel_sums = {}\n",
    "dict_of_all_mut_name_sums = {}\n",
    "for name, df in dict_of_all_grouped_MH.items():\n",
    "    print(name)\n",
    "    types = pd.DataFrame()\n",
    "    states = pd.DataFrame()\n",
    "    types = df.groupby('Type').aggregate({'count': 'sum'})\n",
    "    states = df.groupby('state').aggregate({'count': 'sum'})\n",
    "    mut_names = df.groupby(['Mut name','state','Type','position','Right_MH','Left_MH']).aggregate({'count': 'sum'})\n",
    "\n",
    "    dict_of_all_type_sums[name] = types\n",
    "    dict_of_all_state_sums[name] = states\n",
    "    dict_of_all_mut_name_sums[name] = mut_names\n",
    "\n",
    "#make summary table of counts of 'state' at each sample \n",
    "#     States: Intact, DSB, NHEJ (indels)\n",
    "dict_of_all_state_sums\n",
    "states_df = pd.DataFrame()\n",
    "names_list = []\n",
    "for name, df in dict_of_all_state_sums.items():\n",
    "    names_list.append(name)\n",
    "    states_df = pd.concat([states_df, df], axis=1)\n",
    "states_df.columns = names_list\n",
    "column_list = list(states_df.T)\n",
    "column_list\n",
    "states_df = states_df.T\n",
    "states_df = states_df.fillna(0)\n",
    "states_df[\"Total\"] = states_df[column_list].sum(axis=1)\n",
    "states_df\n",
    "#Calculate Percentages\n",
    "temp = states_df.T\n",
    "percent_states_df = temp / temp.iloc[-1]*100\n",
    "\n",
    "states_df.to_csv(save_dir+target_name+'_States_df.csv')\n",
    "percent_states_df.to_csv(save_dir+target_name+'_Percent_States_df.csv')\n",
    "\n",
    "#make table summarize the 'types' at each sample: \n",
    "#Indels (Del, Ins, MH) and DSBs (Precise,guide-side, PAM-side, extended)\n",
    "dict_of_all_type_sums\n",
    "types_df = pd.DataFrame()\n",
    "names_list = []\n",
    "for name, df in dict_of_all_type_sums.items():\n",
    "    names_list.append(name)\n",
    "    types_df = pd.concat([types_df, df], axis=1)\n",
    "types_df.columns = names_list\n",
    "names_list\n",
    "column_list = list(types_df.T)\n",
    "column_list\n",
    "types_df = types_df.T\n",
    "types_df[\"Total\"] = types_df[column_list].sum(axis=1)\n",
    "types_df = types_df.fillna(0)\n",
    "\n",
    "#Calculate Percentages\n",
    "temp = types_df.T\n",
    "percent_types_df = temp / temp.iloc[-1]*100\n",
    "\n",
    "types_df.to_csv(save_dir+target_name+'_Types.csv')\n",
    "percent_types_df.to_csv(save_dir+target_name+'_Percent_Types.csv')\n",
    "\n",
    "#make table summarize the indels at each sample: \n",
    "#sequences grouped by type of indels with column for count of total concensus sequences of this type\n",
    "dict_of_all_mut_name_sums\n",
    "mut_df = pd.DataFrame()\n",
    "names_list = []\n",
    "for name, df in dict_of_all_mut_name_sums.items():\n",
    "    names_list.append(name)\n",
    "    mut_df = pd.concat([mut_df, df], axis=1)\n",
    "mut_df.columns = names_list\n",
    "column_list = list(mut_df.T)\n",
    "mut_df = mut_df.T\n",
    "mut_df[\"Total\"] = mut_df[column_list].sum(axis=1)\n",
    "mut_df = mut_df.fillna(0)\n",
    "#Calculate Percentages\n",
    "temp = mut_df.T\n",
    "percent_mut_df = temp / temp.iloc[-1]*100\n",
    "\n",
    "DSB_df = mut_df.T.query('state != \"NHEJ\"')\n",
    "indel_df = mut_df.T.query('state != \"Putative DSB\"')\n",
    "percent_indel_df = percent_mut_df.query('state != \"Putative DSB\"')\n",
    "percent_DSB_df= percent_mut_df.query('state != \"NHEJ\"')\n",
    "\n",
    "percent_indel_df.to_csv(save_dir+target_name+'_percent_indel.csv')\n",
    "indel_df.to_csv(save_dir+target_name+'_indel.csv')\n",
    "percent_DSB_df.to_csv(save_dir+target_name+'_percent_DSB.csv')\n",
    "DSB_df.to_csv(save_dir+target_name+'_DSB.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting States\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns for Intact and Total, and calculate averages\n",
    "percent_states_df_plot = percent_states_df.drop(percent_states_df.index[[-1,0]])\n",
    "average_state_sum = Calculate_average(percent_states_df_plot)\n",
    "\n",
    "colors = [\n",
    "'#44a1f7','#eb4025']\n",
    "\n",
    "sns.set_palette(sns.color_palette(colors))\n",
    "current_palette = sns.color_palette(colors)\n",
    "sns.palplot(current_palette)\n",
    "my_cmap = ListedColormap(sns.color_palette(colors).as_hex())\n",
    "\n",
    "\n",
    "labels=['0h A','0h B','6h A','6h B','12h A','12h B','24h A','24h B','36h A','36h B','48h A','48h B','72h A','72h B']\n",
    "fig = percent_states_df_plot.T.plot(kind='bar', stacked=True, cmap = my_cmap)\n",
    "plt.gca().legend(['Indels','DSBs'],loc='upper left',ncol = 1, fontsize=14)\n",
    "plt.title(target_name,fontsize=14)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Percent of Indels and DSBs',fontsize=14)\n",
    "fig.set_xticklabels(labels, fontsize=11)\n",
    "plt.savefig(save_dir+target_name+'_states_barplot.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\n",
    "'#eb4025','#44a1f7']\n",
    "\n",
    "sns.set_palette(sns.color_palette(colors))\n",
    "current_palette = sns.color_palette(colors)\n",
    "sns.palplot(current_palette)\n",
    "my_cmap = ListedColormap(sns.color_palette(colors).as_hex())\n",
    "\n",
    "percent_states_df_time = percent_states_df_plot.T\n",
    "percent_states_df_time['time']=[0,0,6,6,12,12,24,24,36,36,48,48,72,72]\n",
    "NHEJ = percent_states_df_time['NHEJ']\n",
    "DSB = percent_states_df_time['Putative DSB']\n",
    "time = percent_states_df_time['time']\n",
    "NHEJ\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(average_state_sum)\n",
    "plt.plot(time, NHEJ,'o', color='#44a1f7')\n",
    "plt.plot(time,DSB, 'o', color='#eb4025')\n",
    "plt.gca().legend(['Indels','DSBs'],loc='upper left',ncol = 1, fontsize=14)\n",
    "plt.title(target_name)\n",
    "plt.xlim(0,74)\n",
    "plt.xlabel('Time [hours]', fontsize=12)\n",
    "plt.ylabel('Molecules (% of Total)',fontsize=14)\n",
    "plt.savefig(save_dir+target_name+'_states_dot_averageLine.pdf', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
